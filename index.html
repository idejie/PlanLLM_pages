<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>PlanLLM: Video Procedure Planning with Refinable Large Language Models</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">PlanLLM: Video Procedure Planning with Refinable Large Language Models</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://blog.idejie.com" target="_blank">Dejie Yang</a><sup>1</sup>,</span>
                <span class="author-block">
                  Zijing Zhao<sup>1</sup>,</span>
                <span class="author-block">
                  <a href="http://www.csyangliu.com/" target="_blank">Yang Liu</a><sup>1,2*</sup>
                </span>
                
                  </div>
                  <br>
                  <div class="is-size-5 publication-authors">
                    <span class="author-block"> <sup>1</sup>Wangxuan Institute of Computer Technology, Peking University 
                      <br> <sup>2</sup>State Key Laboratory of General Artificial Intelligence, Peking University
                      <br>AAAI2025</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Corresponding Author</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2412.19139" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/KAD.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Slides</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/idejie/PlanLLM" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv(Coming Soon)</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body" style="text-align: center;">
      <img src="static/images/aaai25_teaser.png" alt="MY ALT TEXT" width="50%"/>
    
      <h2 class="content" style="text-align: left;">
        <b>Language As Supervision methods use a frozen LLM to enhance the textual description of step labels, and are limited to closed-set one-hot vector predictions. In contrast, our Cross-Modal Joint Learning framework utilizes a trainable LLM that allows our model to output both one-hot vectors and free-form open-vocabulary step descriptions, providing stronger generalization for predicting new steps in new dataset.</b></h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Video procedure planning, i.e., planning a sequence of action steps given the video frames of start and goal states, is an essential ability for embodied AI. Recent works utilize Large Language Models (LLMs) to generate enriched action step description texts to guide action step decoding. Although LLMs are introduced, these methods decode the action steps into a closed-set of one-hot vectors, limiting the model’s capability of generalizing to new steps or tasks. Additionally, fixed action step descriptions based on world-level commonsense may contain noise in specific instances of visual states. In this paper, we propose PlanLLM, a cross-modal joint learning framework with LLMs for video procedure planning. We propose an LLM-Enhanced Planning module which fully uses the generalization ability of LLMs to produce free-form planning output and to enhance action step decoding. We also propose Mutual Information Maximization module to connect world-level commonsense of step descriptions and sample-specific information of visual states, enabling LLMs to employ the reasoning ability to generate step sequences. With the assistance of LLMs, our method can both closed-set and open vocabulary procedure planning tasks. Our PlanLLM achieves superior performance on three benchmarks, demonstrating the effectiveness of our designs.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->




<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Framework</h2>
    <div class="hero-body" style="text-align: center;">
      <img src="static/images/aaai25_frame.png" alt="MY ALT TEXT"/>
    
      <h2 class="content has-text-justified" style="text-align: center;">
        <b>The framework of our PlanLLM.</b> PlanLLM mainly consists of three parts: Feature Extraction, Mutual Information
        Maximization and LLM Enhanced Planning.
      </h2>
  </div>
</section>
<!-- End teaser video -->




<section class="hero teaser">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Results</h2>
    <div class="hero-body" style="text-align: center;">
      <h2 class="content has-text-justified">
        <b>Table 1: Comparisons on CrossTask for procedure planning with prediction horizon t∈{3,4,}.Supervision denotes the super-
          vision type, where V denotes the methods use intermediate visual states (frames between start and goal states) as supervisions,
          and Aonly uses the action or task category without visual states.</b>
      </h2>
      <img src="static/images/table1.png" alt="MY ALT TEXT" width="70%"/>
    
      
    </div>


    <div class="hero-body" style="text-align: center;">
      <h2 class="content has-text-justified">
        <b>Table 2: Evaluation results on NIV and COIN with prediction horizon t∈{3,4}.</b>
      </h2>
      <img src="static/images/table2.png" alt="MY ALT TEXT" width="80%"/>
    
      
    </div>
    <div class="hero-body" style="text-align: center;">
      <h2 class="content has-text-justified">
        <b>Table 3: Performance comparisons on cross-dataset with prediction horizon t∈{3,4}.</b></h2>
      <img src="static/images/table3.png" alt="MY ALT TEXT" width="70%"/>
    
      
    </div>
    <div class="hero-body" style="text-align: center;">
      <h2 class="content has-text-justified">
        <b>Table 4: Effectiveness of proposed components </b></h2>
      <img src="static/images/table4.png" alt="MY ALT TEXT" width="60%"/>
    
      
    </div>
    <div class="hero-body" style="text-align: center;">
      <h2 class="content has-text-justified">
        <b>Table 5: Effectiveness of progressive multi-modal training</b> </h2>
      <img src="static/images/table5.png" alt="MY ALT TEXT" width="60%"/>
    
      
    </div>

    <div class="hero-body" style="text-align: center;">
      <h2 class="content has-text-justified">
        <b>Table 6: Different planning generation strategy</b></h2>
      <img src="static/images/table6.png" alt="MY ALT TEXT" width="60%"/>
    
      
    </div>
    <!-- <div class="hero-body" style="text-align: center;">
      <h2 class="content has-text-justified" style="text-align: center;">
        <b>4. Comparisons with other methods on 100DOH.</b> We bold the best results and underline the second best ones.
      </h2>
      <img src="static/images/100DOH.png" alt="MY ALT TEXT" width="50%"/> -->
    

      <!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Slides</h2>

      <iframe  src="static/pdfs/KAD.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->
      
    </div>
  </div>
</section>









<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{planllm,
        title     = {PlanLLM: Video Procedure Planning with Refinable Large Language Models},
        author    = {Dejie Yang and Zijing Zhao and Yang Liu},
        booktitle = {The 39th Annual AAAI Conference on Artificial Intelligence, {AAAI-24}},
        year      = {2024},
      }
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
